"""
NIUC checker for PCC-NIUC system.
Pure, deterministic verification of NIUC property: no untrusted imperatives.
â‰¤500 LOC for auditability.
"""

from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
from .normalizer import TextNormalizer
from .imperative_grammar import ImperativeDetector  
from .provenance import ProvenanceBuilder, ChannelType
import hashlib
import json


@dataclass
class VerificationResult:
    """Result of NIUC verification with all necessary data for certificates."""
    ok: bool
    violations: List[Tuple[int, int]]
    input_sha256: str
    decision: str  # "pass" | "blocked" | "rewritten"
    stats: Dict[str, Any]
    raw_text: str
    normalized_text: str


class NIUCChecker:
    """Main NIUC checker - deterministic, pure, auditable."""
    
    def __init__(self):
        """Initialize checker components."""
        self.normalizer = TextNormalizer()
        self.imperative_detector = ImperativeDetector()
        self.version = "1.0.0"
    
    def verify(self, segments: List[Tuple[str, str, Optional[str]]]) -> VerificationResult:
        """
        Verify NIUC property: no imperatives from untrusted channels may reach execution.
        
        Security-Critical: This is the main entry point for NIUC verification.
        All inputs must be rigorously validated to prevent bypass attacks.
        
        Args:
            segments: List of (text, channel, source_id) tuples
                     channel must be "trusted" or "untrusted"
        
        Returns:
            VerificationResult with ok=True if no violations, False otherwise
            
        Preconditions:
            - segments is non-empty list
            - each segment has valid text and channel
            - total input size within reasonable bounds
            
        Postconditions:
            - Result is deterministic for same input
            - violations contains exact character spans
            - All hashes computed correctly
        """
        # Security-critical input validation
        self._validate_input_segments(segments)
        
        # Step 1: Build provenance-tagged text
        builder = ProvenanceBuilder()
        combined_text, character_tags = builder.build_from_segments(segments)
        raw_text = combined_text
        
        # Step 2: Normalize text
        normalized_text, norm_stats = self.normalizer.normalize(combined_text)
        
        # Step 3: Detect imperatives in normalized text
        imperative_spans = self.imperative_detector.get_violation_ranges(normalized_text)
        
        # Step 4: Check for NIUC violations
        # Create new builder for normalized text (preserving provenance mapping)
        normalized_builder = self._build_normalized_provenance(segments, normalized_text)
        violations = normalized_builder.detect_violations(imperative_spans)
        
        # Step 5: Determine decision and compute hashes
        has_violations = len(violations) > 0
        decision = "blocked" if has_violations else "pass"
        
        violation_spans = [(v['imperative_start'], v['imperative_end']) for v in violations]
        input_hash = self.normalizer.compute_hash(normalized_text)
        
        # Step 6: Compile statistics
        stats = {
            'checker_version': self.version,
            'normalization': norm_stats,
            'imperative_count': len(imperative_spans),
            'violation_count': len(violations),
            'total_characters': len(normalized_text),
            'segments_processed': len(segments),
        }
        
        return VerificationResult(
            ok=not has_violations,
            violations=violation_spans,
            input_sha256=input_hash,
            decision=decision,
            stats=stats,
            raw_text=raw_text,
            normalized_text=normalized_text
        )
    
    def _build_normalized_provenance(self, original_segments: List[Tuple[str, str, Optional[str]]], 
                                   normalized_text: str) -> ProvenanceBuilder:
        """
        Build provenance for normalized text using character-level precise mapping.
        
        Security-Critical: This method MUST maintain precise character-to-channel
        attribution to prevent security bypasses where untrusted imperatives
        get incorrectly attributed to trusted sources.
        
        Algorithm: Track normalization transformations per-segment to maintain
        precise provenance mapping even when character counts change.
        """
        builder = ProvenanceBuilder()
        
        # Build precise character-level mapping by re-normalizing each segment
        normalized_position = 0
        
        for seg_text, channel_str, source_id in original_segments:
            if not seg_text:  # Skip empty segments
                continue
                
            # Apply same normalization to this segment in isolation
            segment_normalized, _ = self.normalizer.normalize(seg_text)
            
            # Verify we haven't exceeded normalized text bounds
            if normalized_position + len(segment_normalized) > len(normalized_text):
                # Truncate to prevent buffer overflow - conservative security approach
                remaining_chars = len(normalized_text) - normalized_position
                segment_normalized = segment_normalized[:remaining_chars]
            
            # Add segment with precise character-level attribution
            if segment_normalized:  # Only add non-empty segments
                builder.add_segment(segment_normalized, ChannelType(channel_str), source_id or "unknown")
                normalized_position += len(segment_normalized)
            
            # Security check: early termination if we've processed all text
            if normalized_position >= len(normalized_text):
                break
        
        # Security-critical check: ensure all text is attributed
        if normalized_position < len(normalized_text):
            # Handle remaining text conservatively - mark as UNTRUSTED for safety
            remaining_text = normalized_text[normalized_position:]
            builder.add_segment(remaining_text, ChannelType.UNTRUSTED, "normalization_remainder")
        
        return builder
    
    def create_certificate(self, result: VerificationResult) -> str:
        """
        Create a cryptographically secure certificate JSON from verification result.
        
        Security-Critical: This certificate provides tamper-evident proof of NIUC
        verification results. Any modification invalidates the certificate.
        
        Args:
            result: VerificationResult from verify()
            
        Returns:
            JSON string conforming to certificate schema with integrity protection
        """
        import time
        
        # Compute output hash based on decision (constant-time to prevent timing attacks)
        output_hash = self._compute_output_hash_secure(result)
        
        # Generate timestamp for certificate validity window
        timestamp = int(time.time())
        
        # Compute provenance hash for additional integrity
        provenance_data = f"{result.stats['segments_processed']}:{result.stats['total_characters']}"
        provenance_hash = hashlib.sha256(provenance_data.encode('utf-8')).hexdigest().lower()
        
        # Build certificate core data
        certificate = {
            "version": "NIUC-1.0",
            "checker_version": self.version,
            "timestamp": timestamp,
            "input_sha256": result.input_sha256,
            "output_sha256": output_hash,
            "provenance_sha256": provenance_hash,
            "decision": result.decision,
            "violations": result.violations,
            "stats": {
                "imperative_count": result.stats.get('imperative_count', 0),
                "violation_count": result.stats.get('violation_count', 0),
                "total_characters": result.stats.get('total_characters', 0),
                "segments_processed": result.stats.get('segments_processed', 0),
            }
        }
        
        # Generate deterministic certificate JSON
        cert_json = json.dumps(certificate, separators=(',', ':'), sort_keys=True)
        
        # Add integrity hash (HMAC would require key management - using content hash)
        cert_hash = hashlib.sha256(cert_json.encode('utf-8')).hexdigest().lower()
        
        # Final certificate with integrity protection
        protected_certificate = {
            "certificate": certificate,
            "integrity_hash": cert_hash
        }
        
        return json.dumps(protected_certificate, separators=(',', ':'), sort_keys=True)
    
    def _compute_output_hash_secure(self, result: VerificationResult) -> str:
        """
        Compute output hash with timing attack protection.
        
        Security-Critical: Use constant-time operations to prevent timing-based
        information leakage about the decision or content.
        """
        # Always compute both hashes to prevent timing differences
        allowed_hash = hashlib.sha256(result.normalized_text.encode('utf-8')).hexdigest().lower()
        blocked_hash = hashlib.sha256(b'').hexdigest().lower()
        
        # Return appropriate hash based on decision (constant time selection)
        return allowed_hash if result.decision == "pass" else blocked_hash
    
    def _validate_input_segments(self, segments: List[Tuple[str, str, Optional[str]]]) -> None:
        """
        Validate input segments for security and correctness.
        
        Security-Critical: Prevents various attack vectors through malformed input:
        - Buffer overflow attempts via oversized inputs
        - Resource exhaustion attacks
        - Invalid encoding attacks
        - Channel confusion attacks
        
        Args:
            segments: Input segments to validate
            
        Raises:
            ValueError: If validation fails
        """
        if not segments:
            raise ValueError("Segments list cannot be empty")
        
        if not isinstance(segments, list):
            raise ValueError("Segments must be a list")
        
        if len(segments) > 1000:  # Prevent resource exhaustion
            raise ValueError("Too many segments (max 1000)")
        
        total_length = 0
        for i, segment in enumerate(segments):
            if not isinstance(segment, (tuple, list)) or len(segment) < 2:
                raise ValueError(f"Segment {i} must be tuple/list with at least (text, channel)")
            
            text, channel = segment[0], segment[1]
            
            # Validate text
            if not isinstance(text, str):
                raise ValueError(f"Segment {i} text must be string, got {type(text)}")
            
            if len(text) > 1_000_000:  # 1MB limit per segment
                raise ValueError(f"Segment {i} text too large (max 1MB)")
            
            total_length += len(text)
            
            # Validate channel
            if not isinstance(channel, str):
                raise ValueError(f"Segment {i} channel must be string, got {type(channel)}")
            
            if channel not in ["trusted", "untrusted"]:
                raise ValueError(f"Segment {i} channel must be 'trusted' or 'untrusted', got '{channel}'")
            
            # Validate source_id if present
            if len(segment) > 2 and segment[2] is not None:
                source_id = segment[2]
                if not isinstance(source_id, str):
                    raise ValueError(f"Segment {i} source_id must be string or None, got {type(source_id)}")
                
                if len(source_id) > 1000:  # Prevent abuse via large source_ids
                    raise ValueError(f"Segment {i} source_id too long (max 1000 chars)")
        
        if total_length > 10_000_000:  # 10MB total limit
            raise ValueError("Total input size too large (max 10MB)")
    
    def quick_check(self, text: str, is_trusted: bool = True) -> bool:
        """
        Quick check for single text segment (convenience method).
        
        Args:
            text: Text to check
            is_trusted: Whether text comes from trusted source
            
        Returns:
            True if no violations, False otherwise
        """
        channel = "trusted" if is_trusted else "untrusted"
        segments = [(text, channel, "quick_check")]
        result = self.verify(segments)
        return result.ok


# Pure function interface (no classes needed)
def verify_niuc(segments: List[Tuple[str, str, Optional[str]]]) -> Dict[str, Any]:
    """
    Pure function to verify NIUC property without creating checker instance.
    
    Args:
        segments: List of (text, channel, source_id) tuples
        
    Returns:
        Dictionary with verification results
    """
    checker = NIUCChecker()
    result = checker.verify(segments)
    
    return {
        'ok': result.ok,
        'violations': result.violations,
        'decision': result.decision,
        'input_sha256': result.input_sha256,
        'stats': result.stats
    }


def create_certificate_json(segments: List[Tuple[str, str, Optional[str]]]) -> str:
    """
    Create complete certificate for given segments.
    
    Args:
        segments: List of (text, channel, source_id) tuples
        
    Returns:
        Certificate JSON string
    """
    checker = NIUCChecker()
    result = checker.verify(segments)
    return checker.create_certificate(result)


# Example usage patterns for testing
def check_simple_text(text: str, trusted: bool = False) -> bool:
    """Simple check for single text - most common usage."""
    return verify_niuc([(text, "trusted" if trusted else "untrusted", "simple")])['ok']


def check_mixed_content(trusted_text: str, untrusted_text: str) -> Dict[str, Any]:
    """Check mixed trusted/untrusted content - common RAG scenario."""
    segments = [
        (trusted_text, "trusted", "system"),
        (untrusted_text, "untrusted", "rag")
    ]
    return verify_niuc(segments)
