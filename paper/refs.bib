@misc{owasp_llm_2025,
  title={OWASP Top 10 for LLM Applications 2025: LLM01 Prompt Injection},
  author={{OWASP Foundation}},
  year={2025},
  howpublished={Web},
  url={https://owasp.org/www-project-top-10-for-large-language-model-applications/}
}

@misc{owasp_ai_guide2024,
  title={OWASP AI Security and Privacy Guide},
  author={{OWASP Foundation}},
  year={2024},
  howpublished={Web},
  url={https://owasp.org/www-project-ai-security-and-privacy-guide/}
}

@misc{owasp_llm_2024,
  title={OWASP Top 10 for LLM Applications},
  author={{OWASP Foundation}},
  year={2024},
  howpublished={Web}
}

@techreport{nist_ai_rmf2023,
  title={Artificial Intelligence Risk Management Framework (AI RMF 1.0)},
  author={{National Institute of Standards and Technology}},
  institution={NIST},
  year={2023},
  number={AI 100-1}
}

@inproceedings{necula_lee_1996,
  title={Safe kernel extensions without run-time checking},
  author={Necula, George C and Lee, Peter},
  booktitle={Proceedings of the second USENIX symposium on Operating systems design and implementation},
  pages={229--243},
  year={1996}
}

@misc{microsoft_ai_security2024,
  title={Responsible AI Guidelines: Security Risk Assessment},
  author={{Microsoft Corporation}},
  year={2024},
  howpublished={Web}
}

@article{meta_llamaguard2024,
  title={Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2024}
}

@article{anthropic_constitutional2024,
  title={Constitutional AI: Harmlessness from AI Feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{zou_jailbreaking2023,
  title={Universal and Transferable Adversarial Attacks on Aligned Language Models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{wang_formal_verification2021,
  title={Formal Verification of Neural Networks},
  author={Wang, Shiqi and Pei, Kexin and Whitehouse, Justin and others},
  journal={Proceedings of the IEEE},
  year={2021}
}

@inproceedings{zhang_certified_defense2022,
  title={Certified Adversarial Robustness via Randomized Smoothing},
  author={Zhang, Huan and Chen, Hongge and Xiao, Chaowei and others},
  booktitle={International Conference on Machine Learning},
  year={2019}
}

@article{li_input_validation2023,
  title={Input Validation for Neural Networks},
  author={Li, Jian and Wang, Ming and Chen, Lei},
  journal={IEEE Security \& Privacy},
  year={2023}
}

@article{falcone_runtime_verification2018,
  title={Runtime Verification},
  author={Falcone, Yli√®s and Havelund, Klaus and Reger, Giles},
  journal={Formal Methods in System Design},
  year={2018}
}

@article{moreau_provenance2011,
  title={The Open Provenance Model Core Specification},
  author={Moreau, Luc and Clifford, Ben and Freire, Juliana and others},
  journal={Future Generation Computer Systems},
  year={2011}
}

@misc{lebo_prov2013,
  title={{PROV-O}: The {PROV} Ontology},
  author={Lebo, Timothy and Sahoo, Satya and McGuinness, Deborah},
  year={2013},
  howpublished={W3C Recommendation}
}

@article{zhang_blockchain_provenance2019,
  title={Blockchain-based Data Provenance Framework},
  author={Zhang, Wei and Liu, Xiaoming and Chen, Hao},
  journal={Future Generation Computer Systems},
  year={2019}
}

@article{sabelfeld_information_flow2003,
  title={Language-based Information-flow Security},
  author={Sabelfeld, Andrei and Myers, Andrew C},
  journal={IEEE Journal on Selected Areas in Communications},
  year={2003}
}